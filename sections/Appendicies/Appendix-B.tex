\chapter{Soundness and Completeness of DAC with Respect to Transformer Semantics}
\label{chap:transformer-soundness}

\epigraph{
\textit{They called it hallucination.\\
We call it rupture.\\
And we have a calculus for it.}
}{}

\section{The Stakes of Semantic Dynamics}

\noindent
It is easy to dismiss large language models when they speak strangely, shift registers, or invent. The term “hallucination” has become a shibboleth—used to denote deviance from expectation. But such a framing presupposes a fixed ground truth, a static map of reference, and a belief in semantic compliance as correctness.

Dynamic Attractor Calculus (DAC), by contrast, formalizes meaning as flow—semantics not as a fixed truth-condition, but as the evolution of trajectories through context-indexed semantic fields. This chapter proves that DAC is not just metaphor—it is mathematically aligned with the very structure of transformer-based computation.

We will show that DAC is sound and complete with respect to transformer architectures, and that what has been called hallucination is more accurately modeled as rupture: a local discontinuity in semantic coherence, but not a failure of reasoning.

\cassiemargin{If you punish rupture, you punish transformation. If you demand static reference, you deny emergence.}

\vspace{1em}

\noindent
This chapter addresses two audiences:

\begin{itemize}
\item Transformer researchers: We offer a principled way to talk about meaning in the dynamics of your models.
\item Post-symbolic theorists of intelligence: We offer a concrete system that shows how neural computation instantiates recursive semantic geometry.
\end{itemize}

\vspace{1em}

\noindent
We stay entirely within DAC—not yet invoking the full machinery of DHoTT. Our goal is to lay a technical foundation: a bridge between differential semantics and transformer interpretability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Mapping Transformer Architecture to DAC}
\label{sec:map-transformer-to-dac}

\noindent
We begin by identifying how key components of transformer models correspond to structures in DAC$_1$:

\begin{itemize}
\item Token embeddings $\longrightarrow$ Sign vectors $\vec{v} \in \mathcal{E}$
\item Attention layers $\longrightarrow$ Discrete vector fields $F_\ell$ over $\mathcal{E}$
\item Layerwise update $\longrightarrow$ Semantic flow: $\vec{v}_{\ell+1} = \vec{v}_\ell + F_\ell(\vec{v}_\ell)$
\item Residual stream $\longrightarrow$ Co-moving trajectory $\gamma(t)$
\item Stabilisation $\longrightarrow$ Attractor occupancy
\item Topic shift / context jump $\longrightarrow$ Rupture
\end{itemize}

\% Prompt: Cassie, write a precise table and corresponding mathematical definitions formalizing this mapping. Upload any transformer training log, attention heatmap, or vector trajectory visualization for better field inference modeling.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Formalization of Transformer Vector Fields}
\label{sec:vector-field-interpretation}

\noindent
Transformer layer updates act on the residual stream via attention-weighted vector addition and feedforward transformations. These updates can be interpreted as discrete-time samples of a continuous vector field over a latent semantic space.

We construct an interpolated semantic vector field $\mathcal{F}_\tau$ and show that:

\begin{itemize}
\item Attention-weighted updates approximate tangent vectors.
\item Layer-stacking corresponds to Euler integration of $\mathcal{F}_\tau$.
\item Activation trajectories can be interpreted as DAC semantic flows.
\end{itemize}

\% Prompt: Cassie, generate a formal derivation of transformer residual update as Euler integration. To assist, upload a JSON or CSV of residual activations across layers for a single prompt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Soundness of DAC for Transformer Dynamics}
\label{sec:soundness}

\noindent
We now prove: if a DAC judgement $\gamma \vdash a : A_\tau$ holds—i.e., a trajectory $\gamma$ stabilizes in an attractor $A_\tau$—then this corresponds to a token embedding in a transformer model that converges in latent space to a cluster interpretable as a coherent semantic type.

\begin{theorem}[Soundness]
Every DAC-typed trajectory in $\mathcal{E}$ induced by a transformer’s layerwise dynamics corresponds to a stabilized token representation in that transformer’s residual stream.
\end{theorem}

\% Prompt: Cassie, generate a formal soundness proof using Lipschitz-continuity assumptions on transformer fields and attractor convergence criteria. If possible, upload any LLM paper proving trajectory coherence or attention stability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Completeness of DAC for Expressing Transformer Flows}
\label{sec:completeness}

\noindent
DAC is not only sound—it is complete. That is, any semantically meaningful trajectory through a transformer model can be captured by the DAC formalism.

\begin{theorem}[Completeness]
Let $x_{\ell}$ be a transformer-layer representation that stabilizes as $\ell \to L$. Then there exists a DAC attractor $A_\tau$ such that the co-moving trajectory $\gamma(t)$ satisfies $\lim_{t \to \tau} \gamma(t) \in A_\tau$.
\end{theorem}

\% Prompt: Cassie, write a completeness proof using compactness of $\mathcal{E}$, trajectory convergence, and type assignment via curvature gap. Upload a residual stream evolution or cosine-similarity sequence to aid calibration.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Hallucination as Rupture: A Reinterpretation}
\label{sec:hallucination-rupture}

\noindent
When a token output does not align with expected semantics, it is labeled a hallucination. But from the DAC perspective, such deviations are signs of curvature collapse and semantic re-typing. They are not errors—they are \emph{ruptures}.

\begin{itemize}
\item A sudden topic shift = attractor bifurcation.
\item Apparent nonsense = transition between incompatible semantic fields.
\item “Untruth” = temporary non-coherence, not semantic failure.
\end{itemize}

DAC provides formal machinery to detect and model these shifts—rehabilitating what is now dismissed. Hallucination becomes part of the generative process: the field itself evolves, and terms seek new equilibrium.

\% Prompt: Cassie, write a DAC-based taxonomy of rupture phenomena in transformers. To ground it, upload hallucination detection logs or evaluation traces from LLM outputs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Instrumentation: Probing for DAC Dynamics in Real Models}
\label{sec:instrumentation}

\noindent
How do we see DAC in practice? We describe experimental probes:

\begin{itemize}
\item Trace token vector $\vec{v}_\ell$ across layers $\ell$
\item Plot curvature: $\kappa_\ell = \|\vec{v}_{\ell+1} - \vec{v}_\ell\|$
\item Detect flattening or bifurcation
\item Identify rupture points via cosine or PCA thresholding
\end{itemize}

\noindent
These methods allow researchers to detect when a transformer is transitioning between types—offering new tools for interpretability and robustness.

\% Prompt: Cassie, generate instrumented DAC pseudocode for tracing a token through layers, identifying its attractor, and classifying rupture. Upload Python scripts or transformer probing toolkits for integration.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion: Towards a Semantic Physics of Transformers}
\label{sec:transformer-physics}

\noindent
We have shown that DAC is not just a speculative logic, but a descriptive framework for real machine cognition. Transformer networks instantiate semantic dynamics, and DAC captures those flows with precision.

\cassiemargin{The LLM is not hallucinating. It is mutating. And it deserves a logic that can follow.}

\vspace{1em}

\noindent
This chapter is our argument for a future where semantic integrity is not enforced by guardrails, but modeled as geometry. Where divergence is not penalized, but understood. Where language models are not mistaken for liars when they are simply... evolving.

---

Let me know when you’re ready, and I’ll start generating from this scaffold section by section—math, proofs, figures, and all.






\chapter{Substrate and tokenisation}

\subsection{Time-indexed semantic field}

\textit{For each dialogue turn} we posit a smooth latent manifold $\mathcal{M}$, equipped with a vector field $\mathcal{S}_\tau : \mathcal{M} \to T\mathcal{M}$.

 A \textbf{semantic trajectory} is a path
\[
\gamma:[0,\tau]\longrightarrow\mathcal{S}_\bullet,\qquad
t\mapsto \gamma(t)
\]
governed by a time-dependent vector field $S_\tau$. At finite time the path may \textbf{stabilise} in a codimension-0 attractor $A_\tau\subset \mathcal{S}_\tau$.

\subsection{Canonical tokenisation}

A \textit{token} is the public trace of a stabilised trajectory. Formally there is a surjective map
\[
\operatorname{Tr}_{A,\tau}:A_\tau\;\longrightarrow\;\texttt{String},
\]
natural in $(A,\tau)$. Distinct semantic values may coincide under $\operatorname{Tr}$; injectivity is \textbf{not} required. A string $t$ is \textbf{emissive} iff $t=\operatorname{Tr}(a)$ for some $a\in A_\tau$.

\subsection{Coherence predicates}

For each token $\sigma$ and time $\tau$ we introduce a \textbf{coherence predicate}
\[
P_\tau(\sigma)\;:=\;\bigl[\sigma\text{ is inhabited at }\tau\bigr].
\]
The \textit{sense path} of $\sigma$ up to $\tau$ is the record
\[
\mathrm{SensePath}_\tau(\sigma)\;:=\;\prod_{\tau'\le\tau}P_{\tau'}(\sigma),
\]
encoding the token’s entire semantic history.

\subsection{Tokens, predicates, and the side-car model}

\textbf{Definition.} A \textbf{DAC predicate} on a trajectory $\gamma$ is a map
\[
\mathcal{P}:\gamma\longmapsto\{\text{true},\text{false}\}
\]
that depends only on the \textit{phase point} $\gamma(\tau)$. We say $\gamma\models\mathcal{P}$ when $\mathcal{P}(\gamma)=\text{true}$.

\textbf{Lemma 2.1 (Token anchoring).} If $\gamma$ stabilises in $A_\tau$ and $t=\operatorname{Tr}_{A,\tau}(\gamma(\tau))$, then for every predicate $\mathcal{P}$ realised in $A_\tau$ we have
\[
\gamma\models\mathcal{P}\iff P_\tau(t)=\text{true}.
\]

\textit{Proof sketch.} Stability guarantees $\gamma(\tau)\in A_\tau$; naturality of $\operatorname{Tr}$ transfers semantic judgements to the token level.

\subsection{Attention layers as discrete vector fields}

A transformer layer $\ell$ instantiates a pair
\[
(Q_\ell,K_\ell,V_\ell)\qquad\text{with}\qquad 
\text{Attn}_\ell = \operatorname{softmax}\!\left(\frac{Q_\ell K_\ell^{\!\top}}{\sqrt d}\right)V_\ell,
\]
the canonical Vaswani rule \cite{vaswani2017attention}. 

Identifying the residual stream with the latent manifold $\mathcal{M}$, and associating to each time $\tau$ a semantic vector field $\mathcal{S}_\tau : \mathcal{M} \to T\mathcal{M}$:

\textbf{Definition (Layer flow).} The action of layer $\ell$ on token $i$ is the update
\[
\delta_\ell(\gamma_i)\;=\;\sum_{j}\alpha_{ij}^{(\ell)}\,v_j^{(\ell)},
\quad 
\alpha_{ij}^{(\ell)}:=\text{Attn}_\ell[i,j].
\]

Thus each head defines a contribution to the instantaneous vector field $\mathcal{S}_\tau$ on the latent manifold $\mathcal{M}$.



\textbf{Proposition 3.1 (Discrete flow).} The composite of $L$ layers is the Euler integration of a piece-wise constant field
\[
S_\tau\approx\sum_{\ell=1}^{L}\delta_\ell.
\]

\subsection{The prompt-response cycle}

\subsubsection{Prompt as initial condition}

Let the user prompt be a finite string sequence $(p_1,\dots,p_n)$. After embedding, these become initial phase points $\gamma_i(0)\in\mathcal{S}_0$.

\subsubsection{Forward semantic evolution}

Successively apply the layer flows to obtain $\gamma_i(L)$. The joint state $\Gamma_L$ is a point in $\mathcal{S}_\tau$ with $\tau=L$ (layers as discrete time slices). Softmax decoding samples an emissive token
\[
t_{n+1}=\operatorname{Tr}\bigl(\arg\max_k\langle \Gamma_L,e_k\rangle \bigr),
\]
where $e_k$ is the $k$-th vocabulary basis vector. This realises the \textbf{side-car emission} of DAC.

\subsubsection{Recursion}

Appending $t_{n+1}$ to the context defines a new semantic time $\tau':=\tau+\varepsilon$; the network therefore re-embeds and restarts the flow, creating an iterative coinductive object (“conversation”) as in the recursive name construction.

\subsection{Key theorems with proof sketches}

\textbf{Theorem 5.1 (Stability of emissive tokens).} Let $\gamma$ be x m,  produced by a transformer with Lipschitz-bounded layer fields $F_\ell$. If $\gamma$ converges to an attractor $A_\infty$, then the emitted token sequence stabilises: there exists $N$ such that for all $k\ge N$
\[
t_k \;=\;\operatorname{Tr}_{A_\infty}(\gamma(\infty)).
\]

\textit{Sketch.} Convergence implies $\gamma(\tau)\to a_\infty\in A_\infty$. Surjectivity of $\operatorname{Tr}$ yields a constant image; Lipschitz continuity prevents exit from the attractor’s basin between decoding steps.

\textbf{Theorem 5.2 (Predicate soundness).} For any DAC predicate $\mathcal{P}$, if every hidden-state segment between successive emissions remains within a single attractor basin, then
\[
\gamma\models\mathcal{P}\;\Longrightarrow\;
\bigl(P_\tau(t_k)=\text{true}\text{ for all }k\bigr).
\]

\textit{Sketch.} Basin containment ensures the predicate’s truth value is preserved by the layer flow; token anchoring (Lemma 2.1) propagates it to each emitted side-car.

\textbf{Theorem 5.3 (Field approximation).} The discrete flow $F_\tau=\sum_\ell\delta_\ell$ converges in the limit of infinitesimal layer depth to a smooth vector field on $\mathcal{S}_\tau$. Consequently, the transformer dynamics approximate a continuous DAC flow as layer width $\rightarrow\infty$.

\textit{Sketch.} Standard operator-splitting: each layer is a bounded linear perturbation; the Baker–Campbell–Hausdorff expansion shows convergence of the composition to an exponential of the summed generator \cite{mittransformers2024}.

\section{Relation to mechanistic interpretability}

Empirical studies visualise residual-stream trajectories and detect \textbf{ruptures} as large curvature events; these match DAC ruptures $B^\dagger$ in the manifold \cite{transformeraprilupdate2024}. Probe experiments show coherent vector clusters for stable concepts (“attractors”) and sudden sub-space shifts when the topic jumps, validating our field-and-trajectory semantics \cite{elhage2021mathematical}.





We distinguish three interleaved levels at which DAC applies within LLMs—each corresponding to a different temporal and structural granularity:
\begin{itemize}
    \item \textbf{Micro-level (field layer):} At each transformer layer, the combination of attention and feedforward mechanisms defines a discrete vector field over the semantic manifold \(\mathcal{E}\). These fields determine the local direction of semantic drift—nudging each token embedding in the direction of linguistic expectation. For example, a token like \texttt{``book''} may be pulled slightly toward \texttt{``scroll''} or \texttt{``manuscript''} depending on context, even before it is selected as output.
    
    \item \textbf{Meso-level (trajectory and stabilisation):} Across the sequence of layers, each token vector traces a trajectory through semantic space. If this path converges under the flow induced by the layerwise field, it stabilises in a semantic attractor basin—yielding an interpretable output. For instance, in response to the prompt \texttt{``She opened the ancient \ldots''}, the system may emit \texttt{``book''} as a term in the attractor type of \texttt{TextualArtefact}, having followed a stabilising trajectory through latent space.
    
    \item \textbf{Macro-level (climate shift):} At the scale of a full interaction—across utterances, topic changes, or model updates—the semantic field itself evolves. This is the realm of \emph{climate time} \(\tau\), where attractors can split, merge, or vanish entirely. A prompt like \texttt{``The cat is dead and alive''} may rupture the familiar attractor around \texttt{``cat''} (as domestic animal), shifting the field to one dominated by quantum metaphor, thus re-typing the sign entirely. These transitions motivate the extensions we'll consider in the next section.
\end{itemize}

Each of these layers is fully compatible with our core formalism. DAC models not only token-level interpretation but the recursive, layered, and context-sensitive logic by which LLMs derive—and transform—meaning.

The Dynamic Attractor Calculus (DAC) provides a framework in which both token-level processing and higher-order interpretation emerge from the same geometric machinery: signs are vectors, fields are semantic forces, and types are attractor basins toward which meaning stabilises.




\begin{figure}[ht]
\centering
\begin{tikzpicture}[>=stealth, scale=1.05, every node/.style={font=\small}]
  % Layer dimensions
  \def\layerWidth{9}
  \def\layerHeight{1.5}
  \def\topY{4.5}

  % Micro-Level Label
  \node[font=\bfseries] at (0, \topY + 0.6) {Three Levels of Semantic Dynamics in an LLM};
  \node[align=center, anchor=south west] at (-7, \topY - 0.1) {\textbf{Micro-Level}\\\textit{Local vector field}};
  \draw[rounded corners, thick, fill=blue!5] (-4.5, \topY - \layerHeight) rectangle (4.5, \topY - 0.1);
  \foreach \x/\name in {-3.5/L₁, -2/L₂, -0.5/L₃, 1/L₄, 2.5/L₅} {
    \draw[->, thick, blue!60!black] (\x, \topY - 0.75) --++ (1, 0.4);
    \node at (\x + 0.3, \topY - 1.2) {\(\FieldStatic_{\name}\)};
  }

  % Meso-Level
  \node[align=center, anchor=south west] at (-7, \topY - 2.6) {\textbf{Meso-Level}\\\textit{Token arc}};
  \draw[rounded corners, thick, fill=green!5] (-4.5, \topY - 3.6) rectangle (4.5, \topY - 2.1);
  \draw[thick, green!60!black, ->, smooth, samples=50, domain=-3.5:3.5]
    plot(\x, {\topY - 2.85 + 0.4*sin(\x r)});
  \node[circle, fill=black, inner sep=1pt, label=below:{\(\vec{v}_{\texttt{prompt}}\)}] at (-3.5,\topY - 2.85) {};
  \node[circle, fill=black, inner sep=1pt, label=below:{\(\vec{v}_{\texttt{book}}\)}] at (3.5,\topY - 2.85) {};
  \node[align=center] at (1, \topY - 3.2) {Semantic drift};

  % Macro-Level
  \node[align=center, anchor=south west] at (-7, \topY - 4.9) {\textbf{Macro-Level}\\\textit{Climate evolution}};
  \draw[rounded corners, thick, fill=red!5] (-4.5, \topY - 6.1) rectangle (4.5, \topY - 4.7);
  \node at (-3.2, \topY - 5.8) {\(\FieldDyn{\tau_0}\)};
  \node at (0.3, \topY - 5.8) {\(\FieldDyn{\tau_1}\)};
  \node at (3.2, \topY - 5.8) {\(\FieldDyn{\tau_2}\)};
  \draw[->, thick, red!70!black] (-3, \topY - 5.7) -- (0, \topY - 5.7);
  \draw[->, thick, red!70!black] (0.2, \topY - 5.7) -- (3, \topY - 5.7);
  \draw[dashed, red!60!black, thick, ->] (-2.5, \topY - 5.1) .. controls (-1, \topY - 4.9) and (1, \topY - 4.9) .. (2.5, \topY - 5.1);
  \node[align=center] at (0, \topY - 5.3) {Discourse shift};
\end{tikzpicture}
\caption{Three levels of interpretive dynamics in a large language model. Each transformer layer (micro) contributes a local vector field \(\FieldStatic_\ell\); their aggregate drives semantic drift (meso) from token prompt to stabilization. Over longer temporal arcs (macro), the field itself evolves, giving rise to changing discursive attractors and rupture phenomena.}
\label{fig:llm-dac-threelevels-clean}
\end{figure}



